Transactions on Mergeable Objects
Deepthi Devaki Akkoorath, and Annette Bieniusa
University of Kaiserslautern, Kaiserslautern, Germany
{akkoorath,bieniusa}@cs.uni-kl.de

Abstract. Destructible updates on shared objects require careful handling of concurrent accesses in multi-threaded programs. Paradigms such
as Transactional Memory support the programmer in correctly synchronizing access to mutable shared data by serializing the transactional
reads and writes. But under high contention, serializable transactions
incur frequent aborts and limit parallelism. This can lead to a severe
performance degradation.
In this paper, we propose mergeable transactions which provide a consistency semantics that allows for more scalability even under contention.
Instead of aborting and re-executing, object versions from conflicting updates on shared objects are merged using data-type specific semantics.
The evaluation of our prototype implementation in Haskell shows that
mergeable transactions outperform serializable transactions even under
low contention while providing a structured and type-safe interface.
Keywords: Concurrent programming, Transactional memory, Mergeable objects, Relaxed Consistency

1

Introduction

In imperative programming languages, data structures are in general mutable,
and updates are executed in-place. Therefore, the effect of an update is immediately reflected on the data structure. If the data structure is shared between
multiple threads, the programmer must synchronize potential concurrent accesses to shared state to prevent memory corruption and often ensure progress
by rendering updates visible to all threads.
Data structures that implement an abstract data type are often called objects (akin to objects in object-oriented programming). The correctness condition
that is traditionally applied to shared concurrent objects is linearizability [12].
An object is linearizable if the result of concurrent operations is equivalent to
some legal sequential execution of these operations. For example, concurrent increments of a linearizable counter have to be executed in a sequential order to
prevent the loss of updates. This limits the inherent parallelism of an application
and imposes high cost due to synchronization.
The final publication is availale at Springer via http://dx.doi.org/10.1007/978-3319-26529-2 23

In contrast, (purely) functional programming languages, such as Haskell’s
core language, employ referential transparency. Pure functions do not update destructively. Thus, data structures are immutable by default. Though immutability implies thread-safety, it limits how concurrently running threads can exchange information. To overcome this restriction, Haskell offers different monadic
interfaces supporting in-place updates and shared memory synchronization, the
most prominent being: IO references (IORef), mutable references (MVars), and
transactional variables (TVars).
For example, shared references to an (immutable) data item of type a can
be encapsulated as IO references IORef a. IO references are intialized when
created, and can be operated on using the following functions:
newIORef
:: a -> IO (IORef a)
readIORef :: IORef a -> IO a
writeIORef :: IORef a -> a -> IO ()

In addition, the function atomicModifyIORef allows to atomically apply a function on the referenced object in a thread-safe way:
atomicModifyIORef :: IORef a -> (a -> (a,b)) -> IO b

All calls to atomicModifyIORef need to be serialized to achieve atomicity for
reading and modifiying the value. Haskell’s MVars impose even more synchronization by blocking access to objects between calls to takeMVar and putMVar.
Transactional variables (TVars) provide a very similar interface, though their
access is restricted to memory transactions. Transactions in this context are sequences of reads and writes that are transparently synchronized by the Software Transactional Memory (STM) system [9]. All operations on TVars within a
transaction are executed atomically, and isolated from concurrent threads, thus
providing a consistent view of the state. Yet again, when transactions concurrently operate on the same TVar, with at least one thread updating the variable,
the operations conflict. Transactions thus fail their serializability certification
check and have to re-execute [21].
Semantically, serializability is unnecessarily strict for a multitude of applications. For example, Fig. 1 shows the code snippet for kmeans clustering from the
STAMP benchmark suite[16]. The K-means algorithm partitions n data points
into k clusters such that the total distance for the data point to their respective
cluster centre is minimized. Classical TMs serialize all transactions that access
the same cluster center. However, the only requirement for correctness of the
algorithm is that after all points are processed newcenter and numElems must
contain the sum of all points and the number of points that belong to that cluster, respectively. Even with relaxed transactions [18, 19, 5], conflicts and hence
aborts can still arise when updates cannot be serialized.
To optimize the synchronization on shared mutable data structures, we introduce mergeable objects. Instead of blocking or aborting updates to objects for
serializability, updates are first applied to thread-local object versions. Instead
of a get/set interface, mergeable objects therefore implement abstract data types
with type-specific read and update operations. When committing the locally performed changes to shared memory, the different versions of an object are merged

assign clusters (x,y) = do
let cluster = nearestPoint clusters (x,y)
let center = newcentre cluster
atomically $ do
x’ <- readTVar (xcord center)
writeTVar (xcord center) (x’ + x)
y’ <- readTVar (ycord center)
writeTVar (ycord center) (y’ + y)
n <- readTVar (numElems cluster)
writeTVar (numElems cluster) (n+1)
thread clusters points = mapM_ (assign clusters) points

Fig. 1. Kmeans: Computations by a thread using serializable transactions.

based on the object’s semantics. Updates become visible to other threads only
after the merge operation is called.
We propose Mergeable Transactional Memory (MTM) based on mergeable
objects with relaxed consistency semantics (Section 3). Similar to snapshot isolation, MTM transactions read from a consistent snapshot and operate concurrently on shared objects. Instead of aborting and re-executing in case of conflicts,
transactions commit their changes by merging states of concurrently updated objects. All updates from a transaction become visible together. An efficient merge
operation enables MTM to execute multiple updates in parallel to other threads
and execute the merge inside the critical section.
If newcenter and numElems in Fig.1 are represented using mergeable counters (Section.2) instead of raw integers, transaction can commit by merging
the values, thus eliminating aborts. Moreover, we can rewrite the algorithm
from Fig.1 to Fig.2 where a transaction (represented by eventually) process
all points. MTM then executes it without synchronisation with other threads,
thus allowing more parallelism. With serializable transactions, this would result
in more conflicts and sequential execution of transactions.

thread clusters points = eventually $ mapM_ (assign clusters) points
assign clusters (x,y) = do
let cluster = nearestPoint clusters (x,y)
let center = newcentre cluster
x’ <- readCVar (xcord center)
writeCVar (xcord center) (incrBy x’ x))
Y’ <- readCVar (ycord center)
writeCVar (ycord center) (incrBy y’ y)
c’ <- readCVar (numElems cluster)
writeCVar (numElems cluster) (incrBy c’ 1)

Fig. 2. Kmeans: Larger transactions using MTM

The paper makes the following contributions:

class Counter {
int x = 0;
synchronized void inc() {
x = x+1;
}
}

type Counter = IORef Int
inc :: Counter -> IO ()
inc c = atomicModifyIORef (\x -> x+1,
()) c

Fig. 3. Linearizable Counter in a) Java and b) Haskell.

– We introduce the notion of mergeable objects and propose a classification of
mergeability (Section 2).
– We introduce a programming model, MTM based on mergeable objects and
transactions, and describe an algorithm for implementing the model (Section
3).
– We present a prototype implementation of MTM in Haskell (Section 4) and
evaluate several use cases (Section 5).

2

Mergeable Objects

Instead of a get/set interface, mergeable objects implement abstract data types
with type-specific operations. The update operations on mergeable object thus
differ from that of linearizable objects in imperative programming; the latter
provides in-place updates while operations on mergeable objects conceptually
modify a local copy of the object. The result of updates on mergeable objects
is visible to other threads only after the merge operation is called. Depending
on the actual data types, mergeability of objects can be achieved in two ways,
semantic mergeability and structural mergeability.
Semantic Mergeability: Exploiting object semantics to define the merge function
has been successfully applied in Conflict-free Replicated Data Types (CRDTs)[23]
in the context of distributed database systems. State-based CRDTs rely on
lattice-based monotonic data values where the merge computes the least upper bound. Operation-based CRDTs re-execute updates that were issued on the
local object instance against the global object, therefore requiring commutativity
of concurrent updates to achieve consistency despite different orders of update
application at the different replicas.
As an example, consider a shared counter that can be incremented concurrently by different threads. Figure 3 shows implementations with explicit synchronization in Java and in Haskell. For the mergeable counter in Fig. 4, the
increment operations are collected and combined locally into a variable v, while
a separate merge operation integrates the results of the local operations into the
global state.
The merge operation for the counter in this case is trivial as all update operations commute. In general, CRDTs employ a number of mechanisms to achieve
deterministic results for objects with non-commutative operations, e.g. maintaining tombstones for sets where elements can be added and removed. While

data Counter = Counter (IORef Int) Int
inc :: Counter -> Counter
inc (Counter g v) = Counter g (v+1)
read :: Counter -> Int
read (Counter g v) = do
x <- readIORef g
return (x+v)
merge :: Counter -> IO ()
merge (Counter g v) = do
atomicModifyIORef (\x.x+v, ()) g
return Counter g 0

Fig. 4. Mergeable counter in Haskell.

CRDTs have been successful in avoiding costly synchronization in replicated
data stores, employing the known specifications of CRDTs in multi-/many-core
programs seems prohibitively expensive. In our work, we therefore focus on variants of CRDTs that are optimized for multi-/many-core programs.
Structural Mergeability: While the merge operation for the counter can be implemented in a simple and efficient way, we have to employ different strategies for
larger, composed data structures such as lists and sets. We adopt techniques that
have been developed in the context of persistent data structure [7]. A persistent
data structure is a mutable data structure that offers accessibility to multiple
versions. This technique is widely used to implement purely functional data
structures efficiently, in particular linked data structures such as lists, trees etc.
When multiple threads modify the data structure, each thread executes updates
on a thread-local version of the object, without the need for copying the entire
data structure into thread-local storage. The merge operation is then reduced
to adjust pointers in the local and global version to incorporate the updates in
the global version; hence the name structural mergeability. The merge operation
must preserve the semantics of the abstract data type by resolving potential
semantic conflicts due to concurrent updates.

T1

T1
head

head
T2

T2

a. While threads T1 and T2 are accessing.

b. After thread T1 merges.

T1
head
T2

c. After thread T2 merges.
Fig. 5. Structural mergeability of bags.

As an example for structural mergeability, consider an add-only bag implemented as a persistent linked list. A bag is a set data structure allowing duplicate
elements to be added. Here, threads can concurrently add elements without violating its semantical correctness. An implementation of a mergeable version of
the bag is illustrated in Figure 5. The head points to the first node of the global
version accessible to all threads. Adding an element to the bag adds a new node
at the head of the linked list local to the thread. This results in a multi-headed
list. Figure 5a shows the bag after threads T1 and T2 have added two and three
elements, respectively, and before merging. The list pointed to by T1 represents
the view of the bag to thread T1 , similarly for T2. Both versions share the nodes
of the elements that have been added before the threads started. When merging
T1, it updates the global head to point to T1 (Fig. 5b). When merging T2, it
has to update both the global head and the local tail of T2 to include changes
of T1 in the merge (Fig. 5c). The merge of an add-only bag is efficient because
it requires manipulation of only two pointers.

3

Mergeable Transactions

To leave the triggering of the merge to the programmer poses a number of issues.
For example, the programmer might forget to call the function at all. Merging
updates to different objects is not atomic, thus possibly violating invariants. We
therefore enhance the programming model for mergeable objects with a weak
form of transactions.
Mergeable Transactional Memory (MTM) allows to compose operations on
shared objects. Akin to STM, MTM guarantees atomicity, isolation and (weak)
consistency for dynamic transactions. In contrast to STM, conflicting updates
from concurrently executed transactions do not lead to aborts, but are merged
during commit.
MTM does not provide serializability. Instead it provides a weak consistency
described by the following properties:
– commits are totally ordered.
– reads and updates satisfies the program order.
– All reads from a transaction are guaranteed to observe a consistent prefix of
the committed updates, and preceding updates from the same transaction.
– The consistent prefix includes previously committed updates from the current thread, thus obeying the program order.
3.1

Operational Semantics of MTM

To specify the consistency semantics of MTM transactions, we introduce a callby-need core calculus, Λmtm , with an operation semantics based on transition
rules. Figure 6 shows the syntax of Λmtm . It relies on disjoint sets of variables
(V ar) and references (Ref ). A value is either a reference r, a mergeable value
m, a function, a monadic return, an integer i or unit ().

x ∈ Var, r ∈ Ref
v ∈ Val ::= r | m | λx.e | return e | i | ()
e ∈ Exp ::= v | x | e e | e >
>= e | forkIO e | eventually e | commit Θ e | new e |
read e | write e | e + e | e ∗ e | ...
Fig. 6. Syntax of Λmtm .

Expressions are given as values, variables, function application, monadic
bind, thread fork, MTM transactions, and arithmetic expressions. The expressions marked in gray do not appear in source programs, but represent dynamically generated locations and intermediate system states arising during commits.
t ∈ ThreadId
Θ ∈ Heap
= Ref * Exp
P ∈ ThreadPool = ThreadId * Exp
Fig. 7. State-related definitions.

A program state P ; Θ is a pair consisting of a thread pool P (partial mapping
of thread identifiers to expressions) and a heap Θ. A reference l corresponds to an
object allocated on the heap Θ. Dereferencing Θ(l) yields the associated object,
while a heap update Θ[l 7→ e] returns a heap that is identical to Θ, but maps l
to e. Similarly, we denote updates in the thread pool P by P {t 7→ e}.
The evaluation of a program starts in an initial state {t0 7→ e}; ∅ with an
empty heap and a main thread t0 . The evaluation stops when the program
reaches a final state of the form {t0 7→ v0 , . . . , tn 7→ vn }; Θ. The reduction rules
in Fig. 8 define the semantics of the language constructs. Each global reduction
step  nondeterministically selects a thread from P , thus modeling an arbitrary
thread scheduling.
The IO Monad is the top-level evaluation context. Rule IO-Monad enables
the execution of reductions within the current context. Spawning a thread (rule
Spawn) adds a new entry with a fresh thread identifier to the thread pool and
returns unit to the parent thread. A transactional expression is evaluated against
a copy of the current heap (rule Txn), possibly using multiple transactional
transitions denoted by ⇒.
Within a transaction, reading an object returns the value referenced in the
heap (rule Read). Similarly, after applying the updates the resulting value is
written back to the heap (rule Write), replacing the previous value. When
allocating a new object, rule New ensures that the heap is extended using a
fresh reference (i.e. one that has not been used in the heap or in concurrently
running threads). The initial value of the object is then added to the transactionlocal heap instance under the new reference.
Finally, an evaluated transaction is represented as a commit record consisting
of the local heap copy, containing possible modifications, and the expression to

Evaluation contexts:
E ::= [] e | [] >
>= e | [] + e | v + [] | [] ∗ e | ...
Expression evaluation →:
(λx.e) e0 → e[e0 /x]

e → e0
E[e] → E[e0 ]

i+j →i⊕j

i∗j →i⊗j

return e0 >
>= e → e e0
Thread evaluation :
t0 fresh
P {t 7→ E[forkIO m]}; Θ  P {t 7→ E[return ()], t0 →
7 m}; Θ

Spawn

e; Θ ⇒ return e0 ; Θ0
P {t 7→ E[eventually e]}; Θ  P {t 7→ E[commit Θ0 e0 ]}; Θ
P {t 7→ E[commit Θ0 e]}; Θ  P {t 7→ E[return e]}; Θ d Θ0
e → e0
P {t 7→ E[e]}; Θ  P {t 7→ E[e0 ]}; Θ

Txn
Commit
IO-Monad

Evaluation steps in transaction ⇒:
Θ(r) = m
E[read r]; Θ ⇒ E[return m]; Θ

Read

Θ(r) = m
E[write r]; Θ ⇒ E[return ()]; Θ[r 7→ m]

Write

r fresh
E[new m]; Θ ⇒ E[return r]; Θ[r 7→ m]
e → e0
E[e]; Θ ⇒ E[e0 ]; Θ
Fig. 8. Operational Semantics for Λmtm .

New
MTM-Monad

be returned. Rule Commit then applies atomically the heap modifications to
the globally shared heap and returns. The changes from the local heap copy Θ0
are propagated to the current globally shared heap Θ by merging the individual
entries with the thread-local ones. The function d :: Heap×Heap → Heap defines
the heap merge:

0

merge m n if Θ(r) = m, Θ (r) = n
0
(Θ d Θ )(r) = m
if r ∈
/ dom(Θ), Θ0 (r) = m


n
if r ∈
/ dom(Θ0 ), Θ(r) = n
3.2

Properties of MTM

Based on the operational semantics for Λmtm , we can now further characterize
MTM transactions.
MTM allows non-serializable transactions. By rule Txn, the heap-modifying
side-effects of a transaction eventually e are not immediately applied to the
shared global state, but deferred to another reduction step under rule Commit. Depending on the scheduling, other transactions may also execute without
committing their changes yet. If there are read-write dependencies between the
transactions, it is not possible to construct a reduction sequence yielding the
same final state.
All updates are eventually applied to the shared state. The type specific merge
during the commit ensures that concurrent updates are merged deterministically
into a consistent state of the object.
All updates performed by a transaction are made visible atomically. By rule
Commit, all updates from a transaction are merged to the globally shared heap
in one step, which guarantees atomicity.
All reads performed by a transaction appear to be executed at a single point of
time. In addition to publishing the updates atomically, transactions are executed
on a consistent snapshot; i.e. a snapshot in which either all updates from some
transaction that committed before the snapshot time are visible or none. All read
operations within a transaction are guaranteed to see the state of objects from
a consistent snapshot taken at the time when the transaction started. Rule Txn
shows that all operations inside a transaction are executed against the same state
Θ. Although there could be concurrently executing transactions, their updates
are not globally visible.
3.3

Algorithm

An algorithm for implementing the semantics of MTM transactions is given in
Figure 9. To guarantee that a transaction never tries to read an object that has
been modified by another transaction while executing (leading to a read-write
conflict), we apply a multi-versioning scheme for mergeable objects. As previous studies have shown [18, 19, 5], multi-versioning of objects can be efficiently
employed to achieve permissive transactions.

A shared mutable reference to a mergeable object which can be accessed in a
MTM transaction is represented by var. A var references a list of versions. Each
version contains a value of the object and its version identifier.
A transaction txn maintains a snapshot id sid in addition to a read and
write sets which are represented as maps. When the transaction starts, its sid is
assigned to be the current value of a globalclock. The operations of the transaction
are executed on the snapshot identified by this sid which includes updates from
all transactions committed before this time.

1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30:
31:
32:
33:
34:
35:

txn: {sid, Map writeset, Map readset}
var : {versions, lock}
versions : [{val, versionid}]
function beginTransaction(txn)
txn.sid ← globalclock
txn.writeset ← ∅
txn.readset ← ∅
end function
function read(var,txn)
if txn.writeset.contains(var ) then
val ← txn.writeset.lookup(var )
else if txn.readset.contains(var ) then
val ← txn.readset.lookup(var )
else
val ← readVersion(var, txn.sid)
txn.readset.add(var,val)
end if
return val
end function
function write(var, val, txn)
txn.writeset.insert(var,val )
end function
function commit(txn)
lockAll(txn.writeset)
versionid ← globalclock ++
for all (var,val) ∈ txn.writeset do
v’ ← readLatestVersion(var)
newval ← merge(v’,val)
writeNewVersion(var, newval, versionid)
end for
unlockAll(txn.writeset)
end function
Fig. 9. MTM Algorithm

. read your own writes

A var is accessed using the read and write methods. When reading, if the
write set or read set contains a local copy of var, it is returned. Otherwise, the
version corresponding to the transaction’s sid is obtained and inserted in the
read set. A new value of the object is written back to var using method write,
which inserts the value in the write set. Reading an object does not necessarily
pass over the entire object. Depending on the actual representation of the object,
a read might only be reading a reference.
When committing, the transaction acquires a lock on all objects in its write
set. This ensures atomicity when two transactions tries to commit to same object.
To prevent deadlocks, locks are obtained in a predefined order. Next, a new
version id is generated from the current global clock value. The objects updated
in the transaction are then merged with the latest version available, using the
objects’ merge method, hereby creating new versions.
Fig.10 shows the versioned read and write functions. The function writeNewVersion adds the new value with its vid to the head of list of versions.
Since globalclock is incremented during commit, the sid of a transaction always
denotes the version id of a committed transaction or a concurrently committing
transaction. When reading from the list of versions of a var, if the required version is not available, a concurrent transaction might be committing that version.
Hence, it waits for the lock to be released before retrieving a version with an
id equal or smaller than its sid. If the lock is released, it means that there is
no other transaction which could potentially commit a version required by this
transaction. This guarantees that a transaction always reads from a consistent
snapshot identified by its sid.

4

MTM in Haskell

We implemented a prototype of MTM in Haskell. Harris et al. [9] have highlighted the benefits of Haskell’s monadic type system for composing STM actions and restricting access to transactional variables to the STM monad. MTM
is implemented analogously to the STM monad, though with different semantics.
For the MTM programming model, we provide an MTM monad (Fig.11). The
shared mergeable objects used in MTM transactions are of type CVar; CVar1
stands for convergent variables indicating that concurrent versions converge into
a consistent state. Every operation executed on a CVar must be an MTM action.
These actions can be sequentially combined using monadic bind. The function
eventually :: MTM a -> IO a

takes an MTM action, executes it, and returns the result. Using function modifyCVar
to update a CVar guarantees that the mergeable values does not escape a transaction’s scope.
The type specification ensures that mergeable objects are accessed only inside
a MTM transaction. These objects must be of class Mergeable and define a
merge function. Fig.12 shows the implementation of two mergeable objects. The
1

The name MVar for mergeable variables is already used in Haskell.

1: function readVersion(var, vid )
2:
v ← var.versions
3:
if v.head.versionid ≥ vid then
4:
vr ← v.head
5:
else
6:
waituntil (not locked(var ))
. Wait for a concurrent committer to write
required version
7:
vr ← var.versions.head
8:
end if
9:
while vr.versionid > vid do
10:
vr ← vr.next
11:
end while
12:
return vr.val
13: end function
14:
15: function readLatestVersion(var )
16:
return var.versions.head.val
17: end function
18:
19: function writeNewVersion(var, val, vid )
20:
v ← newVersion(val,vid )
21:
var.versions.addHead(v)
22: end function
Fig. 10. Versioned read and write operations in MTM.

Counter contains two integers, one representing the global value and the other
the thread-local increments. The merge adds the local increments to the global
value g and resets the local increments to 0. The LWWRegister implements a

last-writer-wins register, where the last merge overwrites the previous value.

Example The following example shows how to program with CVars and the
MTM monad in Haskell.
addToBag :: Int -> CVar (Bag Int) -> CVar (Counter) -> MTM [Int]
addToBag e bag size = do {
; b <- modifyCVar bag (add e)
; s <- modifyCVar size (incrBy 1)
; return (toList b)
}

The function addToBag inserts an element to some bag and increments a counter
representing the size of the bag. It returns then the elements from the bag in
a list, including the added element e, but excluding elements that have been
concurrently added. When calling the function using eventually addToBag x
b s with some bag b and size counter s, the library guarantees that both shared
objects are atomically updated and have consistent values.

data MTM a = ...
data CVar a = ...
-- MTM Functions
eventually :: MTM a -> IO
newCVar
:: Mergeable a
readCVar
:: Mergeable a
modifyCVar :: Mergeable a

a
=> a -> MTM (CVar a)
=> CVar a -> MTM a
=> CVar a -> (a -> a) -> MTM a

-- Mergeable Objects
class Mergeable a where
merge :: a -> a -> a

Fig. 11. Interface for MTM in Haskell.

-- Mergeable Counter
data Counter = Counter Int Int
instance Mergeable Counter where
merge (Counter g _) (Counter _ i) =
Counter (g+i) 0
newCounter::Counter
newCounter = Counter 0 0
value :: Counter -> Int
value Counter g l = g+l
incrBy :: Int -> Counter -> Counter
incrBy i (Counter g l) =
Counter g (l+i)

-- LWWRegister
type LWWReg = Int
instance Mergeable LWWReg where
merge g l = l
-- Mergeable Bag
data Bag a = Bag [[a]] [a]
instance CRDT (Bag a) where
merge (Bag g _) (Bag _ i) =
Bag (i:g) []
newIntBag :: Bag Int
newIntBag = Bag [[]] []
add :: a -> Bag a -> Bag a
add e (Bag g l) = Bag g (e:l)

Fig. 12. Mergeable objects in Haskell.

5

Evaluation

To evaluate the applicability of MTM we ran microbenchmarks, comparing our
MTM implementation as Haskell library with a library implementation of a
STM algorithm based on 2-phase-commit (2PC) (similar to TL2 [6]) and GHC’s
STM implementation. GHC’s STM is tightly integrated with the runtime system
and employs a number of optimization techniques with respect to GC interaction
and scheduling. To approximate the runtime overhead incurred by implementing
MTM as a library, we use the 2PC implemenation as another point of comparison. All experiments were run on a Quad-core 2.4GHz Intel Xeon processor with
two-way hyperthreading, under Linux 2.6.32-64-server Ubuntu x86 64 and GHC
version 7.8.3. The results given are the averages taken over 10 runs for each
benchmark.
Microbenchmarks: Counter and Bag In a first experiment, we compared the
performance of a shared counter and bag under high contention. The STM variants implement the counter as a TVar Int and TVar [Int], while MTM relies
on a mergeable counter and bag, as introduced in Sec. 3. For the experiment,
each thread repeatedly increments the same shared counter. In total, there were
2 × 106 increments distributed over the available number of threads.

50

Time(sec)

40
30
20

Throughput(ops/sec)

GHC-Counter
2PC-Counter
MTM-Counter
GHC-Bag
2PC-Bag
MTM-Bag

10
0
1 2

4

8

16

No.of threads

Fig. 13. Every thread updates once
the same shared object in a transaction.

1.1e+06
1e+06
900000
800000
700000
600000
500000
400000
300000
200000
100000
0
1

2

4

8

No. of Objects per transaction

Fig. 14. Every thread updates M objects
in a transaction

As Fig. 13 shows, the performance of the library version of STM degrades
quickly while both MTM and GHC’s STM handle the contention more gracefully.
To evaluate the throughput, we chose a workload where each transaction
updates m randomly selected objects from a pool of n objects: the larger the
pool (n), the lower the probability of contention; the larger the transaction size
(m), the higher the probability of conflicts as it is more likely that transaction
executions overlap. For n = 8 and various transaction size, MTM yields better
performance than the STM implementations, even under low contention (Fig.
14).
Application: K-means: To see how actual applications benefit from the MTM
programming model, we reimplemented the K-means benchmark from the STAMP
benchmark suite [16] in Haskell described in Section.1.
For the version running GHC’s STM and MTM a cluster centre is updated
inside a transaction after processing every data point (here: 106 points). We also
derived an alternative implementation to exploit the semantics of MTM, MTMOpt, where all points assigned to some thread are processed together, and cluster
centers are updated atomically. This version runs longer transactions, but has
less frequent updates to cluster centers.
Both under high contention (Fig. 15) and low contention (Fig. 16), MTM-Opt
outperforms GHC and MTM. In particular, MTM-Opt is scalable even under
high contention in contrast to the other versions. The reason is that GHC’s
STM and MTM are blocking during commit, which prohibits scalability when the
number of concurrent transactions is high. In the optimized version, commits are
less frequent and transactions can run in parallel without the need for serializing
the updates to shared memory.

6

Related Work

Software Transactional Memory: Relaxing strong guarantees such as serializability has been considered by different STMs. Multi-versioned STMs [5] and Snap-

250

Time(sec)

200
150

Time(sec)

GHC
2PC
MTM
MTMopt

100
50
0
1 2

4

8

16

No.of threads

Fig. 15. K-means: High contention.

200
180
160
140
120
100
80
60
40
20

GHC
2PC
MTM
MTMopt

1 2

4

8

16

No.of threads

Fig. 16. K-means:Low Contention.

shot Isolation in STMs [19] allow read-only transactions to proceed without any
conflicts. However, there may be aborts in case of write-write conflicts. Different
apporaches have been proposed to avoid abort or restarting of whole transactions by delaying some computations [20] to commit time and re-executing parts
of transaction [5]. Twilight STM [1] allows transaction-specific conflict handling
when inconsistencies are detected in commit phase. MTM focuses on introducing
the conflict handling mechanisms at the object level.
Composable Memory Transactions [9] provide primitives for making serializable transactions composable in Haskell. The authors describe the benefits of
Haskell’s type system and monads to achieve safety and composability of transactions. We have adopted these techniques to implement the MTM monad. However, as MTM transactions do never abort, we restrain from providing additional
operations that support composability such as retry and orElse.
Transactional Boosting [11] is a method which allows operations on highly
concurrent linearizable objects to execute using concurrent transactions, without
the need for acquiring an exclusive lock on the object. A method’s abstract lock
issues a conflict only if two concurrent method invocations are non-commutative;
therefore, concurrent commutative operation on an object can execute without
aborting the transaction. Transactional boosting is a pessimistic approach by
eagerly acquiring locks on the objects. Optimistic Transactional Boosting [10] is
yet another methodology for transforming concurrent data structures to transactional objects. Both approaches take commutativity of operations as the base for
detecting conflicts and thus achieving serializability. In contrast, MTM relies on
object specific conflict resolution which may allow non-commutative operations
to occur in parallel.
Burckhardt et al. [2, 15] propose a programming model for concurrent programs using revisions and isolation types. Each revision is considered a unit of
concurrency. It executes operations on its local copy of the shared data concurrently to other threads. The modified data is visible to the main thread only after
the revision is explicitly joined. The conflicts occurring due to concurrent updates
are resolved using custom merge operation for cumulative types and joinee-wins
strategy for versioned types. Though MTM and the revisions model share similar

semantics in executing operations on consistent snapshots and merging conflicting updates, they target different settings. The revisions programming model is
a fork-join model and is suitable for short-running threads that operate mostly
in isolation. MTM targets long running threads which need to periodically share
data with other threads using transactional semantics.
The Phase Reconciliation mechanism [17] detects high contention on data
items in in-memory databases. It then switches to a split phase where the transactions update a local per-core copy of the contended data in parallel. After
the split phase, the per-core copies are merged and the transactions proceed
to execute using classical concurrency control techniques. Whether transactions
can be executed in the split phase, is decided based on the commutativity of
operations, thus preserving sequential consistency.
Monotonic and Mergeable data structures: Conflict Free Replicated Data
Types (CRDT) [22, 23] are replicated data types with mergeable semantics used
in distributed database systems with eventual consistency. A state-based CRDT
takes its values from a semi-lattice. Two states of the same objects are merged
by taking the least upper bound in the semi-lattice. Op-based CRDTs, on the
other hand, exploit commutativity of updates to deterministically converge the
states of two replicas.
LVars [13, 14] are lattice-based data structures used for deterministic parallel
programming in Haskell. The put operation changes an LVar’s state in such a way
that it monotonically increases in the lattice structure. Updates from concurrent
threads on an LVar result in the same state, irrespective in which order they occur, thus guaranteeing determinism. The merge function computes always the
least upper bound according to the lattice. LVars focus on deterministic and efficient execution for parallel programming models to support producer/consumer
like application.
We believe that lattice-based data structures such as LVars and CRDTs are
beneficial for deterministic merging and verifying the correctness of applications.
However, it is not trivial how to construct efficient merge operation in order
to be useful in an optimistic transactional model to improve performance. In
this paper, we have discussed mergeable data structures which are not lattice
structures.
Confluent persistent data structures [7, 8] allow operations on multiple versions of a data structure. These operations (e.g. concatenation, union) are constructed in a way such that previous versions are still accessible. Confluent persistent data structures are designed to perform these operations efficiently, in
space and time. The applicability of these techniques in mergeable objects is an
interesting topic for future work.
Distributed Systems: Weak consistency models such as eventual consistency
and causal consistency are being widely researched and used in distributed systems. SwiftCloud [24] is a system that supports client-side replication and uses
CRDTs to deterministically merge conflicting updates, while supporting Transactional causal+ consistency. Burckhardt et al. [3] present the idea of eventually
consistent transactions and an implementation technique which provides these

semantics. Global Sequence Protocol [4] provides a programming model for replicated data stores and a weak consistency model relying on a global total order
of updates. Though many recent works have studied eventual consistency in
distributed database systems, few have addressed its applicability in multi-core
programs. In this paper, we have discussed a way to achieve weak consistency
in software transactions.

7

Conclusion

We have presented mergeable transactions as an alternative to the often too strict
semantics of serializable transactions. Using abstract data type specifications,
mergeable objects provide type-specific merge functions. We discussed semantic
and structural mergeability as design alternatives for efficient merge functions
and showed how to apply them to counters and bags. Our evaluation results
on a prototype implementation in Haskell underline that for many workloads,
especially on long running transactions, MTM outperforms standard STM, by
eliminating the necessity for rollback.
In future work, we plan to extend MTM with a broader variety of mergeable
objects and efficient implementation techniques. We also want to investigate
the applicability of the concept in other programming paradigms, where more
optimizations regarding the space and time complexity of mergeable objects are
possible than in Haskell. It will be further interesting to study the possibility
of co-existence of mergeable objects with non-mergeable objects in transaction,
where aborts should be only induced when non-mergeable objects conflict.
Acknowledgments This research is supported in part by the European FP7
project 609 551 SyncFree.

References
1. Bieniusa, A., Middelkoop, A., Thiemann, P.: Brief announcement: Actions in the
Twilight - concurrent irrevocable transactions and inconsistency repair. In: Proceedings of the 29th Annual ACM Symposium on Principles of Distributed Computing, PODC 2010, Zurich, Switzerland, July 25-28, 2010. pp. 71–72 (2010)
2. Burckhardt, S., Baldassin, A., Leijen, D.: Concurrent programming with revisions
and isolation types. In: Proceedings of the ACM International Conference on Object Oriented Programming Systems Languages and Applications. pp. 691–707.
OOPSLA ’10 (2010)
3. Burckhardt, S., Leijen, D., Fhndrich, M., Sagiv, M.: Eventually consistent transactions. In: Seidl, H. (ed.) Programming Languages and Systems, Lecture Notes
in Computer Science, vol. 7211, pp. 67–86. Springer Berlin Heidelberg (2012)
4. Burckhardt, S., Leijen, D., Protzenko, J., Fähndrich, M.: Global Sequence Protocol: A Robust Abstraction for Replicated Shared State. In: Boyland, J.T. (ed.) 29th
European Conference on Object-Oriented Programming (ECOOP 2015). vol. 37,
pp. 568–590. Schloss Dagstuhl–Leibniz-Zentrum fuer Informatik, Dagstuhl, Germany (2015)

5. Cachopo, J., Rito-Silva, A.: Versioned boxes as the basis for memory transactions.
Science of Computer Programming 63(2), 172 – 185 (2006), special issue on synchronization and concurrency in object-oriented languages
6. Dice, D., Shalev, O., Shavit, N.: Transactional locking II. In: Dolev, S. (ed.) Distributed Computing, 20th International Symposium, DISC 2006, Stockholm, Sweden, September 18-20, 2006, Proceedings. Lecture Notes in Computer Science, vol.
4167, pp. 194–208. Springer (2006)
7. Driscoll, J.R., Sarnak, N., Sleator, D.D., Tarjan, R.E.: Making data structures
persistent. J. Comput. Syst. Sci. 38(1), 86–124 (Feb 1989)
8. Fiat, A., Kaplan, H.: Making data structures confluently persistent. In: Proceedings
of the Twelfth Annual ACM-SIAM Symposium on Discrete Algorithms. pp. 537–
546. SODA ’01, Society for Industrial and Applied Mathematics (2001)
9. Harris, T., Marlow, S., Peyton-Jones, S., Herlihy, M.: Composable memory transactions. In: Proceedings of the Tenth ACM SIGPLAN Symposium on Principles
and Practice of Parallel Programming. pp. 48–60. PPoPP ’05 (2005)
10. Hassan, A., Palmieri, R., Ravindran, B.: Optimistic transactional boosting. In:
Proceedings of the 19th ACM SIGPLAN symposium on Principles and practice of
parallel programming. pp. 387–388. ACM (2014)
11. Herlihy, M., Koskinen, E.: Transactional boosting: A methodology for highlyconcurrent transactional objects. In: Proceedings of the 13th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming. pp. 207–216. PPoPP
’08 (2008)
12. Herlihy, M.P., Wing, J.M.: Linearizability: A correctness condition for concurrent
objects. ACM Trans. Program. Lang. Syst. 12(3), 463–492 (Jul 1990)
13. Kuper, L., Newton, R.R.: Lvars: Lattice-based data structures for deterministic
parallelism. In: Proceedings of the 2Nd ACM SIGPLAN Workshop on Functional
High-performance Computing. pp. 71–84. FHPC ’13 (2013)
14. Kuper, L., Turon, A., Krishnaswami, N.R., Newton, R.R.: Freeze after writing:
Quasi-deterministic parallel programming with lvars. In: Proceedings of the 41st
ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages.
pp. 257–270. POPL ’14 (2014)
15. Leijen, D., Fahndrich, M., Burckhardt, S.: Prettier concurrency: Purely functional
concurrent revisions. In: Proceedings of the 4th ACM Symposium on Haskell. pp.
83–94. Haskell ’11, ACM, New York, NY, USA (2011)
16. Minh, C.C., Chung, J., Kozyrakis, C., Olukotun, K.: Stamp: Stanford transactional
applications for multi-processing. In: Workload Characterization, 2008. IISWC
2008. IEEE International Symposium on. pp. 35–46 (Sept 2008)
17. Narula, N., Cutler, C., Kohler, E., Morris, R.: Phase reconciliation for contended
in-memory transactions. In: Proceedings of the 11th USENIX Conference on Operating Systems Design and Implementation. pp. 511–524. OSDI’14 (2014)
18. Perelman, D., Fan, R., Keidar, I.: On maintaining multiple versions in stm. In:
Proceedings of the 29th ACM SIGACT-SIGOPS Symposium on Principles of Distributed Computing. pp. 16–25. PODC ’10 (2010)
19. Riegel, T.: Snapshot isolation for software transactional memory. In: In Proceedings
of the First ACM SIGPLAN Workshop on Languages, Compilers, and Hardware
Support for Transactional Computing (TRANSACT06 (2006)
20. Ruan, W., Liu, Y., Spear, M.: Transactional read-modify-write without aborts.
ACM Trans. Archit. Code Optim. 11(4), 63:1–63:24 (Jan 2015)
21. Scott, M.L.: Sequential specification of transactional memory semantics. In: Proceedings of the First ACM SIGPLAN Workshop on Languages, Compilers, and
Hardware Support for Transactional Computing (Jun 2006)

22. Shapiro, M., Preguiça, N., Baquero, C., Zawirski, M.: A comprehensive study of
Convergent and Commutative Replicated Data Types. Rapport de recherche RR7506, INRIA (Jan 2011)
23. Shapiro, M., Preguiça, N., Baquero, C., Zawirski, M.: Conflict-free replicated data
types. In: Proceedings of the 13th International Conference on Stabilization, Safety,
and Security of Distributed Systems. pp. 386–400. SSS’11 (2011)
24. Zawirski, M., Bieniusa, A., Balegas, V., Duarte, S., Baquero, C., Shapiro, M.,
Preguiça, N.: SwiftCloud: Fault-Tolerant Geo-Replication Integrated all the Way
to the Client Machine. Research Report RR-8347 (Oct 2013)

